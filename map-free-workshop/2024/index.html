<!doctype html>
<html lang="en">

<head>
    <title>Map-free Visual Relocalization: Metric Pose Relative to a Single Image</title>
    <meta name="description" content="Map-free visual relocalization ECCV 2024 workshop"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>
    <meta charset="utf-8"/>
    <link rel="icon" href="assets/images/NianticLogo.png"/>

    <!--Facebook preview-->
    <meta property="og:title"
          content="Map-free Visual Relocalization: Metric Pose Relative to a Single Image"/>
    <meta property="og:description"
          content="Map-free Visual Relocalization Competition. An ECCV'24 workshop."/>
    <meta property="og:url" content="https://TODO"/>

    <!--Twitter preview-->
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:title"
          content="Map-free Visual Relocalization: Metric Pose Relative to a Single Image"/>
    <meta name="twitter:description"
          content="Map-free Visual Relocalization Competition. An ECCV'24 workshop."/>

    <!--Style-->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH"
          crossorigin="anonymous"/>

    <link href="css/style.css" rel="stylesheet"
          onerror="this.onerror=null;this.href='https://storage.cloud.google.com/res-recon-experiments/aron-workshop24/20240702/style.css';"/>
    <script src="https://kit.fontawesome.com/746ee6bfa4.js" crossorigin="anonymous"></script>

    <!--<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>-->
    <!--<script src="js/app.js"></script>-->
</head>

<body>
<div class="container">

    <!-- Title -->
    <div class="row" style="text-align:center">
        <div class="col">
            <h1 style="margin-bottom:1.3rem;">Map-free Visual Relocalization:<br/>
                Metric Pose Relative to a Single Image</h1>
            <h4 style="font-size:1.7em;">ECCV 2024 Workshop & Challenge</h4>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Links external -->
    <div class="row" style="text-align:center; margin-top:1rem;">
        <div class="col-12">
            <h4>
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/leaderboard?t=single&f=2024">
                    <nobr>Leaderboard <small>(Single Frame)</small></nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/leaderboard?t=multi9&f=2024">
                    <nobr>Leaderboard <small>(Multi Frame)</small></nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/dataset">
                    <nobr>Dataset</nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://github.com/nianticlabs/map-free-reloc#bar_chart-evaluate-your-method">
                    <nobr>Benchmark<img src="assets/images/github-mark.png" style="max-height: 1.5rem; margin-top: -0.35rem;"/></nobr>
                </a> &emsp;
                <a style="font-size:1.1em; text-decoration: none;"
                   href="https://research.nianticlabs.com/mapfree-reloc-benchmark/submit">
                    <nobr>Submit</nobr>
                </a> &emsp;
                <!--<a style="font-size:1.1em; text-decoration: none;" href="TODO">
                    <nobr>Call for papers</nobr>
                </a>-->
                <a style="font-size:1.1em; text-decoration: none;"
                   href="mailto:map-free-workshop@nianticlabs.com" target="_blank">Contact us</a>
            </h4>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Links internal -->
    <div class="row" style="margin-top:1rem;">
        <div class="col-12">
            <a style="font-size:1.1em; text-decoration: none;" href="#Speakers">
                <nobr>Speakers</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Location">
                <nobr>Location</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Schedule">
                <nobr>Preliminary Schedule</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Posters">
                <nobr>Confirmed Posters</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Accepted_Papers">
                <nobr>Accepted Papers</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Organizers">
                <nobr>Organizers</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Sponsors">
                <nobr>Sponsors</nobr>
            </a>
            <br/>
            <a style="font-size:1.1em; text-decoration: none;" href="#About_the_Challenge">
                <nobr>About the Challenge</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Important_Dates">
                <nobr>Important Dates</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Winners">
                <nobr>Challenge Winners</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Prizes">
                <nobr>Prizes</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Call_for_Papers">
                <nobr>Call for Papers</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Submission_Guidelines">
                <nobr>Submission Guidelines</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#Competition_Requirements">
                <nobr>Competition Requirements</nobr>
            </a> &emsp;
            <a style="font-size:1.1em; text-decoration: none;" href="#FAQ">
                <nobr>FAQ</nobr>
            </a> &emsp;
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Teaser -->
    <div class="row">
        <div class="col-12">
            <!--<img src="assets/images/teaser.jpg"
                 style="display: block; margin: auto; width: 80%; margin-bottom: 1rem;"
                 alt="teaser image"/>-->
            <video width="100%" controls autoplay muted loop style="border-radius: 2%">
                <source src="assets/images/web_mapfree.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Abstract -->
    <div class="row">
        <div class="col-12">
            <p>
                The Map-free Visual Relocalization workshop investigates topics related to
                metric visual relocalization relative to a single reference image instead of
                relative to a map.
                This problem is of major importance to many higher level applications, such as
                Augmented/Mixed Reality, SLAM and 3D reconstruction.
                It is important now, because both industry and academia are debating whether and
                how to build HD-maps of the world for those tasks. Our community is working to
                reduce the need for such maps in the first place.
                <br/>
                <br/>
                We host the first Map-free Visual Relocalization Challenge 2024 competition with
                two tracks:
                map-free metric relative pose from a single image to a single image (proposed by
                <a href="https://github.com/nianticlabs/map-free-reloc">Arnold et al. in ECCV
                    2022</a>) and from a query sequence to a single image (new).
                While the former is a more challenging and thus interesting research topic, the
                latter represents a more realistic relocalization scenario, where the system making
                the queries may fuse information from query images and tracking poses over a short
                amount of time and baseline.
                We invite papers to be submitted to the workshop.
            </p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Speakers -->
    <div class="row">
        <div class="col-12">
            <h3><a id="Speakers">Speakers</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Speakers');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/jakob.jpeg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://jakobengel.github.io/"
                           style="text-decoration: none;" id="Speakers__Jakob_Engel">
                            Jakob Engel<!--
                     --></a>, Meta
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC
                    </p>
                    <p class="speaker-bio">
                        <span class="talk-title">Bio:</span> Jakob Engel joined the Surreal Vision team at Oculus
                        Research in Redmond in 2016, working on the future of 3D-enabled Machine Perception. He did his
                        Bachelor and Master at TU Munich (2009 and 2012), followed up with a PhD at the Computer Vision
                        Group there, headed by Professor Daniel Cremers. He spent 6 months as Intern at Intel Research
                        with Vladlen Koltun, was a Google PhD fellow, and worked with SIEMENS within the Software Campus
                        Initiative. His PhD was about direct visual SLAM, 3D reconstruction, sensor fusion and some cool
                        flying quadrocopter stuff - mostly he developed LSD-SLAM and DSO.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/vincent.png" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://europe.naverlabs.com/people_user_naverlabs/vincent-leroy/"
                           style="text-decoration: none;" id="Speakers__Vincent_Leroy">
                            Vincent Leroy<!--
                     --></a>, Naver Labs Europe
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> Grounding Image Matching in 3D with MASt3R <br/>
                        <span class="talk-title">Summary:</span> The journey from CroCo to MASt3R exemplify a
                        significant paradigm shift in 3D vision technologies. This presentation will delve into the
                        methodologies, innovations, and synergistic integration of these frameworks, demonstrating their
                        impact on the field and potential future directions. The discussion aims to highlight how these
                        advancements unify and streamline the processing of 3D visual data, offering new perspectives
                        and capabilities in map-free visual relocalization, robotic navigation and beyond.
                    </p>
                    <p class="speaker-bio">
                        <span class="talk-title">Bio:</span> Vincent is a research scientist in Geometric Deep Learning
                        at Naver Labs Europe.
                        He joined 5 years ago, in 2019, after completing his PhD on Multi-View Stereo Reconstruction for
                        dynamic shapes at the INRIA Grenoble-Alpes under the supervision of E. Boyer and J-S. Franco.
                        Other than that, he likes hiking in the mountains and finding simple solutions to complex
                        problems.
                        Interestingly, the latter usually comes with the former.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/simon.webp" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://research.google/people/simon-lynen/"
                           style="text-decoration: none;" id="Speakers__Simon_Lynen">
                            Simon Lynen<!--
                     --></a>, Google
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC
                    </p>
                    <p class="speaker-bio">
                        <span class="talk-title">Bio:</span> Simon Lynen is a tech lead manager at Google Zurich. His
                        group focuses on providing high precision mobile-phone localization as part of the Visual
                        Positioning Service (VPS). Devices with Google‚Äôs augmented reality capabilities can leverage VPS
                        to enable global scale location aware experiences such as ARCore CloudAnchors and GoogleMaps
                        LiveView. Simon earned a doctorate at the Autonomous Systems Lab at ETH Zurich with a focus on
                        visual navigation and localization algorithms for robotics, mobile devices, and autonomous cars.
                        As visiting researcher, Simon contributed central pieces to core algorithms of Google‚Äôs ARCore.
                        In talks at TEDx Zurich, ThinkingDigital, Zurich Minds, and scientific conferences, Simon has
                        provided a behind-the-scenes view of the ARCore technology and its latest capabilities.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/torsten.jpg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://tsattler.github.io/"
                           style="text-decoration: none;" id="Speakers__Torsten_Sattler">
                            Torsten Sattler<!--
                     --></a>, CTU Prague
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC
                    </p>
                    <p class="speaker-bio">
                        <span class="talk-title">Bio:</span> Torsten Sattler is a Senior Researcher at CTU. Before, he
                        was a tenured associate professor at Chalmers University of Technology. He received a PhD in
                        Computer Science from RWTH Aachen University, Germany, in 2014. From Dec. 2013 to Dec. 2018, he
                        was a post-doctoral and senior researcher at ETH Zurich. Torsten has worked on feature-based
                        localization methods [PAMI‚Äô17], long-term localization [CVPR‚Äô18, ICCV‚Äô19, ECCV‚Äô20, CVPR‚Äô21] (see
                        also the benchmarks at <a href="https://visuallocalization.net" target="_blank">visuallocalization.net</a>),
                        localization on mobile devices [ECCV‚Äô14, IJRR‚Äô20], and using semantic scene understanding for
                        localization [CVPR‚Äô18, ECCV‚Äô18, ICCV‚Äô19]. Torsten has co-organized tutorials and workshops at
                        CVPR (‚Äô14, ‚Äô15, ‚Äô17-‚Äô20), ECCV (‚Äô18, ‚Äô20), and ICCV (‚Äô17, ‚Äô19), and was / is an area chair for
                        CVPR (‚Äô18, ‚Äô22, ‚Äô23), ICCV (‚Äô21, ‚Äô23), 3DV (‚Äô18-‚Äô21), GCPR (‚Äô19, ‚Äô21), ICRA (‚Äô19, ‚Äô20), and ECCV
                        (‚Äô20). He was a program chair for DAGM GCPR‚Äô20, a general chair for 3DV‚Äô22, and will be a
                        program chair for ECCV‚Äô24.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/speakers/shubham.jpg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://shubhtuls.github.io/"
                           style="text-decoration: none;" id="Speakers__Shubham_Tulsiani">
                            Shubham Tulsiani<!--
                     --></a>, Carnegie Mellon University
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> Rethinking Camera Parametrization for Pose
                        Prediction<br/>
                        <span class="talk-title">Summary:</span> Every student of projective geometry is taught to
                        represent camera matrices via an extrinsic and intrinsic matrix and learning-based methods that
                        seek to predict viewpoints given a set of images typically adopt this (global) representation.
                        In this talk, I will advocate for an over-parametrized local representation which represents
                        cameras via rays (or endpoints) associated with each image pixel. Leveraging a diffusion based
                        model that allows handling uncertainty, I will show that such representations are more suitable
                        for neural learning and lead to more accurate camera prediction.
                    </p>
                    <p class="speaker-bio">
                        <span class="talk-title">Bio:</span> Shubham Tulsiani is an Assistant Professor at Carnegie
                        Mellon University in the Robotics Institute. Prior to this, he was a research scientist at
                        Facebook AI Research (FAIR). He received a PhD. in Computer Science from UC Berkeley in 2018
                        where his work was supported by the Berkeley Fellowship. He is interested in building perception
                        systems that can infer the spatial and physical structure of the world they observe. He was the
                        recipient of the Best Student Paper Award in CVPR 2015.
                    </p>
                </div>
            </div> <!-- speaker -->

            <div class="speaker" style="margin-bottom:3rem;">
                <img src="assets/organizers/victor.jpg" alt="Speaker Image" class="speaker-image"/>
                <div class="speaker-info">
                    <h4 class="speaker-name">
                        <a href="https://www.robots.ox.ac.uk/~victor/"
                           style="text-decoration: none;" id="Speakers__Victor_Adrian_Prisacariu">
                            Victor Adrian Prisacariu<!--
                     --></a>, Niantic and Oxford University
                    </h4>
                    <p class="speaker-bio">
                        <span class="talk-title">Talk title:</span> TBC (opening remarks)
                    </p>
                    <p class="speaker-bio">
                        <span class="talk-title">Bio:</span> Professor Victor Adrian Prisacariu received the Graduate
                        degree (with first class hons.) in computer engineering from Gheorghe Asachi Technical
                        University, Iasi, Romania, in 2008, and the D.Phil. degree in engineering science from the
                        University of Oxford in 2012.<br/>
                        He continued here first as an EPSRC prize Postdoctoral
                        Researcher, and then as a Dyson Senior Research Fellow, before being appointed an Associate
                        Professor in 2017. <br/>
                        He also co-founded <a href="https://6D.ai">6D.ai</a>, where he built
                        APIs to help developers augment reality in ways that users would find meaningful, useful and
                        exciting. The 6D.ai SDK used a standard built-in smartphone camera to build a cloud-based,
                        crowdsourced three-dimensional semantic map of the world all in real-time, in the background.
                        6D.ai was acquired by Niantic in March 2020. He is now Chief Scientist with Niantic. <br/>
                        Victor's research interests include semantic visual tracking, 3-D reconstruction, and SLAM.
                    </p>
                </div>
            </div> <!-- speaker -->

        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Location -->
    <div class="row">
        <div class="col-12">
            <h4><a id="Location">Location</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Location');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h4>
            <hr />
            <h4>üè§üìç Suite 6, South Level Mezzanine &nbsp;&nbsp;&nbsp;<small><a
                    href="https://maps.app.goo.gl/Y4iPgEFpViEKfoYN8" target="_blank">Google Maps</a></small></h4>
            <a href="https://www.google.com/maps/place/Allianz+MiCo+%E2%80%A2+Milano+Convention+Centre/@45.4813272,9.1528774,17z/data=!3m2!4b1!5s0x4786c10d38e671eb:0x1e3146974449414c!4m6!3m5!1s0x4786c112eaeffe77:0x6c1c03719d72cec5!8m2!3d45.4813235!4d9.1554577!16s%2Fg%2F11cs37h0p8?entry=ttu">Allianz
                MiCo ‚Ä¢ Milano Convention Centre</a><br/>
            Viale Eginardo - Gate 2 (Or Piazzale Carlo Magno ‚Äì Gate 16 (for those arriving from Domodossola Metro
            Station) <br/>
            20149 Milano, Italy
        </div> <!-- col -->
    </div> <!-- row -->

    <div class="row">
        <div class="col-3"></div>
        <div class="col-6">
            <a href="assets/images/Allianz%20MiCo_Level_2M.png">
                <img width="100%" src="assets/images/Allianz%20MiCo_Level_2M.png"/>
            </a>
        </div> <!-- col6 -->
        <div class="col-3"></div>
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Schedule -->
    <div class="row">
        <div class="col-12">
            <h3><a id="Schedule">Preliminary Schedule</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Schedule');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />

            <h4>üìÖ&nbsp; &nbsp; &nbsp; On Monday, 30<sup>th</sup> September, 2024, AM </h4>
            <table class="table">
                <thead>
                <tr>
                    <th scope="col" class="text-nowrap">Time</th>
                    <th scope="col">Event</th>
                </tr>
                </thead>
                <tbody>
                <tr>
                    <td class="text-nowrap">09:05 - 09:20</td>
                    <td>
                        Welcome introduction by <a href="https://www.robots.ox.ac.uk/~victor/"
                                                   style="text-decoration: none;">
                        Victor Adrian Prisacariu</a> (Niantic and Oxford University)
                    </td>
                </tr>
                <tr>
                    <td class="text-nowrap">09:25 - 09:55</td>
                    <td><a href="https://jakobengel.github.io/">Jakob Engel</a>, Meta</td>
                </tr>
                <tr>
                    <td class="text-nowrap">10:00 - 10:30</td>
                    <td><a href="https://research.google/people/simon-lynen/">Simon Lynen</a>, Google</td>
                </tr>
                <tr>
                    <td class="text-nowrap">10:30 - 11:00</td>
                    <td>Coffee break and poster session</td>
                </tr>
                <tr>
                    <td class="text-nowrap">11:00 - 11:45</td>
                    <td><a href="https://europe.naverlabs.com/people_user_naverlabs/vincent-leroy/">Vincent Leroy</a>,
                        Naver Labs Europe
                        and Single Frame challenge track winner talk<br/>
                        <i>Grounding Image Matching in 3D with MASt3R</i><br/>
                        The journey from CroCo to MASt3R exemplify a significant paradigm shift in 3D vision
                        technologies. This presentation will delve into the methodologies, innovations, and synergistic
                        integration of these frameworks, demonstrating their impact on the field and potential future
                        directions. The discussion aims to highlight how these advancements unify and streamline the
                        processing of 3D visual data, offering new perspectives and capabilities in map-free visual
                        relocalization, robotic navigation and beyond.
                    </td>
                </tr>
                <tr>
                    <td class="text-nowrap">11:50 - 12:20</td>
                    <td><a href="https://tsattler.github.io/">Torsten Sattler</a>, CTU Prague</td>
                </tr>
                <tr>
                    <td class="text-nowrap">12:25 - 12:55</td>
                    <td><a href="https://shubhtuls.github.io/">Shubham Tulsiani</a>, CMU<br/>
                        <i>Rethinking Camera Parametrization for Pose Prediction</i><br/>
                        Every student of projective geometry is taught to represent camera matrices via an extrinsic and
                        intrinsic matrix and learning-based methods that seek to predict viewpoints given a set of
                        images typically adopt this (global) representation. In this talk, I will advocate for an
                        over-parametrized local representation which represents cameras via rays (or endpoints)
                        associated with each image pixel. Leveraging a diffusion based model that allows handling
                        uncertainty, I will show that such representations are more suitable for neural learning and
                        lead to more accurate camera prediction.
                    </td>
                </tr>
                <tr>
                    <td class="text-nowrap">12:55 - 13:00</td>
                    <td>Closing Remarks and award photos</td>
                </tr>
                </tbody>
            </table>

        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Posters -->
    <div class="row">
        <div class="col-12">
            <h4><a id="Posters">Confirmed posters</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Posters');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h4>
            <hr />
            <ul>
                <li>
                    <a href="https://arxiv.org/abs/2406.09756">Grounding Image Matching in 3D with MASt3R</a><br />
                    Vincent Leroy, Yohann Cabon and J√©r√¥me Revaud <br />
                    <a href="https://europe.naverlabs.com/">Naver Labs Europe</a>
                </li>
                <li><a href="assets/Map_Free_Challenge_DepthMickey.pdf">Improving Map-Free Localization with Depth Supervision</a><br />
                    Hitesh Jain and Sagar Verma <br />
                    <a href="https://www.granular.ai/">Granular AI</a>
                </li>
                <li>
                    <a href="https://arxiv.org/abs/2404.14409">CrossScore: Towards Multi-View Image Evaluation and Scoring</a><br />
                    Zirui Wang, Wenjing Bian, Victor Adrian Prisacariu <br />
                    <a href="https://crossscore.active.vision/">University of Oxford</a>
                </li>
            </ul>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- About the Challenge -->
    <div class="row">
        <div class="col-12">
            <h3><a id="About_the_Challenge">About the Challenge</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('About_the_Challenge');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />
            <p>
                We have extended the Map-free benchmark for the challenge with a sequence-based
                scenario, based on feedback from senior community members.
                Therefore, the challenge consists of two tracks:<br/>
                &nbsp;&nbsp; 1. The original, <strong>single query frame</strong> to single map
                frame task published
                with the <a
                    href="https://storage.googleapis.com/niantic-lon-static/research/map-free-reloc/MapFreeReloc-ECCV22-paper.pdf"
                    target="_blank">ECCV 2022 paper</a>;<br/>
                &nbsp;&nbsp; 2. A new task with <strong>multiple query frames</strong> (9) and their
                mobile device provided, metric tracking poses.
            </p>
            <h5> 1. Single query frame to a single "map" frame</h5>
            <p>
                To recap, the task in the first track consists of from a single query image predict
                the metric relative pose to a single map image without any further auxiliary
                information.
            </p>
            <h5> 2. Multiple query frames (9) to a single "map" frame</h5>
            <p>
                The second track is motivated by the observation that a burst of images, capturing
                small motion, can be recorded while staying true to the map-free scenario: No
                significant data capture or exploration of the environment.<br/>
                At the same time, the burst of images allows the application of multi-frame depth
                estimation and contains strong hints about the scene scale from the IMU sensor on
                device.<br/>
                We created a second version of the test set and <a
                    href="https://research.nianticlabs.com/mapfree-reloc-benchmark/leaderboard?t=multi9&f=2024">leaderboard</a>
                for this track.
            </p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h4><a id="Contact_form">Stay up to date!</a><!--
            --><small><!--
              --><a onclick="copyLinkToClipboard('Contact_form');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h4>
            <hr />
            <p>Please register your interest
                <a href="https://docs.google.com/forms/d/e/1FAIpQLScMKpHBn_fPrFRSpVp9BtiH3DbNRM4pj_8kjWVx-M1SQFrt0w/viewform?usp=sf_link">
                    here</a>, so we can keep you notified about news and updates!</p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h3><a id="Important_Dates">Important Dates</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Important_Dates');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />
            <dl class="row">
                <dt class="col-5">
                    Challenge start
                </dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">21<sup>st</sup> May, 2024</li>
                        <li class="list-inline-item"><span id="day-start-countdown" class="mx-4"></span></li>
                    </ul>
                </dd>

                <dt class="col-5">
                    <span class="workshop-paper">Workshop paper</span> and
                    <span class="extended-abstract">extended abstracts</span> submission deadline
                </dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">&nbsp;2<sup>nd</sup> August, 2024</li>
                        <li class="list-inline-item"><span id="day-paper-submit-countdown"></span></li>
                    </ul>
                </dd>

                <dt class="col-5">
                    <span class="workshop-paper">Workshop paper</span> and
                    <span class="extended-abstract">extended abstracts</span> camera-ready deadline
                </dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">22<sup>nd</sup> August, 2024</li>
                        <li class="list-inline-item"><span id="day-paper-camera-ready-countdown"></span></li>
                    </ul>
                </dd>

                <dt class="col-5">Challenge end</dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">23<sup>rd</sup> August, 2024</li>
                        <li class="list-inline-item"><span id="day-end-countdown"></span></li>
                    </ul>
                </dd>

                <dt class="col-5">
                    Challenge submission <span class="method-description">method description</span> deadline
                </dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">27<sup>th</sup> August, 2024</li>
                        <li class="list-inline-item"><span id="day-describe-countdown"></span></li>
                    </ul>
                </dd>

                <dt class="col-5">Challenge winners announcement</dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">30<sup>th</sup> August, 2024</li>
                        <li class="list-inline-item"><span id="day-winners-countdown"></span></li>
                    </ul>
                </dd>

                <dt class="col-5">Workshop date (ECCV'24)</dt>
                <dd class="col-7">
                    <ul class="list-inline">
                        <!-- note: if you change the date, please change it at the bottom <script> as well -->
                        <li class="list-inline-item">30<sup>th</sup> September, 2024, AM</li>
                        <li class="list-inline-item"><span id="day-workshop-countdown" class="mb-4"></span></li>
                    </ul>
                    <div style="margin-top: -1.1rem;">
                        <small>
                            <a href="http://www.google.com/calendar/event?action=TEMPLATE&dates=20240930T070000Z/20240930T110000Z&text=Map-free%20Visual%20Relocalization%20Workshop%20at%20ECCV%202024%20&location=Allianz+MiCo+%E2%80%A2+Milano+Convention+Centre&details=Map-free%20Visual%20Relocalization%20Workshop%20at%20ECCV%202024%0Ahttps%3A%2F%2Fnianticlabs.github.io%2Fmap-free-workshop%2F2024%20%0A%0AGoogle%20Maps%3A%20https%3A%2F%2Fmaps.app.goo.gl%2Fif1ooCakSvhiEPmR7"
                               target="_blank">[Add to Google Calendar]</a>
                        </small>
                    </div>
                </dd>
            </dl>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Winners -->
    <div class="row">
        <div class="col-12">
            <h3><a id="Winners">üèÜ 2024 Challenge Winners</a><!--
            --><small><!--
              --><a onclick="copyLinkToClipboard('Winners');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />
            <h5>Single Frame <small>(<a href="https://research.nianticlabs.com/mapfree-reloc-benchmark/leaderboard?t=single&f=2024">Leaderboard</a>)</small></h5>
            <dl class="row">
                <dt class="col-4">
                    ü•á <em>MASt3R (Ess.Mat + D.Scale)</em>
                </dt>
                <dd class="col-8">
                    Vincent Leroy, Yohann Cabon and Jerome Revaud <br />
                    Naver Labs Europe <br />
                    <a href="https://arxiv.org/abs/2406.09756">https://arxiv.org/abs/2406.09756</a>
                </dd>
                <dt class="col-4">
                    ü•à <em>interp_metric3d_loftr_3d2d</em>
                </dt>
                <dd class="col-8">
                    Lili Zhao<sup>1</sup>, Zhili Liu<sup>2</sup>, Lei Yang<sup>1</sup>, Meng Guo<sup>1</sup> <br />
                    <sup>1</sup>China Mobile Research Institute, <br />
                    <sup>2</sup>N/A <br />
                    <a href="https://github.com/Shepherddot/An-Implementation-For-Two-View-Metric-Pose-Estimation">https://github.com/Shepherddot/An-Implementation-For-Two-View-Metric-Pose-Estimation</a>
                </dd>
                <dt class="col-4">
                    ü•â <em>Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge</em>
                </dt>
                <dd class="col-8">
                    Mingyu Xiao<sup>1</sup>, Runze Chen <sup>1</sup>, Haiyong Luo<sup>2</sup>, Fang Zhao<sup>1</sup>, Juan Wang<sup>3</sup>, Xue Peng Ma<sup>3</sup> <br />
                    <sup>1</sup>Beijing University of Posts and Telecommunications, <br />
                    <sup>2</sup>Research Center for Ubiquitous Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences <br />
                    <sup>3</sup>Shouguang Cheng Zhi Feng Xing Technology Co., Ltd. <br />
                    <a href="http://arxiv.org/abs/2408.13085">http://arxiv.org/abs/2408.13085</a>
                </dd>
                <dt class="col-4">
                    &nbsp;<img height="18" width="18" src="assets/images/4th-place-medal-low.png" /> <em>Mickey Variant GT_Depth</em>
                </dt>
                <dd class="col-8">
                    Hitesh Jain, Sagar Verma <br />
                    Granular AI <br />
                    <a href="assets/Map_Free_Challenge_DepthMickey.pdf">Map_Free_Challenge_DepthMickey.pdf</a>
                </dd>
            </dl>
            <h5>Multi Frame <small>(<a href="https://research.nianticlabs.com/mapfree-reloc-benchmark/leaderboard?t=multi&f=2024">Leaderboard</a>)</small></h5>
            No accepted entries. <br />
            <!--<ol>
                <li>
                    ü•á <em>MASt3R (Ess.Mat + D.Scale)</em>; <a href="https://arxiv.org/abs/2406.09756">https://arxiv.org/abs/2406.09756</a><br />
                    Vincent Leroy, Yohann Cabon and Jerome Revaud; <br />
                    Naver Labs Europe
                </li>
                <li>
                    ü•à <em>interp_metric3d_loftr_3d2d</em>; <a href="https://github.com/Shepherddot/An-Implementation-For-Two-View-Metric-Pose-Estimation">https://github.com/Shepherddot/An-Implementation-For-Two-View-Metric-Pose-Estimation</a><br />
                    Lili Zhao<sup>1</sup>, Zhili Liu<sup>2</sup>; <br />
                    <sup>1</sup>China Mobile Research Institute,
                    <sup>2</sup>anonymous
                </li>
                <li>
                    ü•â <em>Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge</em>; <a href="http://arxiv.org/abs/2408.13085">http://arxiv.org/abs/2408.13085</a><br />
                    Mingyu Xiao<sup>1</sup>, Runze Chen <sup>1</sup>, Haiyong Luo<sup>2</sup>, Fang Zhao<sup>1</sup>, Juan Wang<sup>3</sup>, Xue Peng Ma<sup>3</sup>; <br />
                    <sup>1</sup>Beijing University of Posts and Telecommunications,
                    <sup>2</sup>Research Center for Ubiquitous Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences
                    <sup>3</sup>Shouguang Cheng Zhi Feng Xing Technology Co., Ltd.
                </li>
                <li><em>Mickey Variant GT_Depth</em>; <a href="assets/Map_Free_Challenge_DepthMickey.pdf">Map_Free_Challenge_DepthMickey.pdf</a><br />
                    Hitesh Jain, Sagar Verma; <br />
                    Granular AI</li>
            </ol>-->
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Prizes -->
    <div class="row">
        <div class="col-12">
            <h3><a id="Prizes">Prizes</a><!--
            --><small><!--
              --><a onclick="copyLinkToClipboard('Prizes');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />
            <p>
                <span class="fs-5">$6000 in prizes will be divided between the top submissions of the two tracks.</span><br />
                Niantic is also seeking partners from the growing community to co-fund and co-judge
                the prizes.
            </p>
            <div class="blockquote">
                <span class="text-light badge bg-gradient" style="background-color: #df471c">Update</span>
                <a href="https://europe.naverlabs.com">Naver Labs Europe</a> has kindly agreed to co-sponsor the challenge with $2000!
            </div>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h3><a id="Call_for_Papers">Call for Papers: ECCV Map-free Visual Relocalization
                Workshop & Challenge 2024</a><!--
            --><small><!--
              --><a onclick="copyLinkToClipboard('Call_for_Papers');"
                    style="cursor: pointer;"> üîó<!--
                    --></a><!--
                  --></small><!--
               --></h3>
            <hr />
            <p>We invite submissions of <span class="workshop-paper">workshop papers</span> and <span class="extended-abstract">extended abstracts</span> to the ECCV Map-free Visual Relocalization
                Workshop & Challenge 2024.
                This workshop aims to advance the field of visual relocalization without relying on pre-built maps.
                The following topics and related areas are of interest:</p>
                <div class="row">
                    <div class="col-6">
                        <ul>
                            <li>visual relocalization,</li>
                            <li>feature-matching,</li>
                            <li>pose regression (absolute and relative),</li>
                            <li>depth estimation (monocular and multi-frame),</li>
                        </ul>
                    </div>
                    <div class="col-6">
                        <ul>
                            <li>scale estimation,</li>
                            <li>confidence and uncertainty,</li>
                            <li>structure-from-motion</li>
                        </ul>
                    </div>
                </div>
            <p><span class="workshop-paper">Workshop paper</span> and <span class="extended-abstract">extended abstract</span> submission deadline: 2<sup>nd</sup> August, 2024. See also <a href="#Important_Dates">Important Dates</a>.<br/>
            Sign up through the <a href="#Contact_form">contact form</a> to stay up to date with future announcements.</p>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h4><a id="Accepted_Papers">üèÜ Accepted Papers (pre-prints!)</a><!--
            --><small><!--
              --><a onclick="copyLinkToClipboard('Accepted_Papers');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h4>
            <hr />
            Here follows a list of pre-prints of the three <span class="workshop-paper">workshop papers</span> accepted to the ECCV Map-free Visual Relocalization Workshop & Challenge 2024:
            <ul>
                <li>
                    <a href="https://arxiv.org/abs/2408.16445v1">Mismatched: Evaluating the Limits of Image Matching Approaches and Benchmarks</a>
                </li>
                <li>
                    <a href="https://arxiv.org/abs/2403.08156">NeRF-Supervised Feature Point Detection and Description</a>
                </li>
                <li>
                    <a href="https://arxiv.org/abs/2404.09271">VRS-NeRF: Visual Relocalization with Sparse Neural Radiance Field</a>
                </li>
            </ul>

        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- Submission Guidelines -->
    <div class="row">
        <div class="col-12">
            <h4><a id="Submission_Guidelines">Submission Guidelines</a><!--
            --><small><!--
              --><a onclick="copyLinkToClipboard('Submission_Guidelines');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h4>
            <hr />

            <div class="row">
                <div class="col">
                    <p>
                        Camera ready versions of accepted <span class="workshop-paper">workshop papers</span> should be
                        submitted in the ECCV main conference camera ready template for your workshop papers.
                        The template can be accessed <a href="https://www.overleaf.com/read/gqtmnkdjsrwq#102a58">
                        here</a> and <a href="https://eccv.ecva.net/Conferences/2024/SubmissionPolicies">here</a>.
                    </p>
                </div> <!-- col -->
            </div> <!-- row -->

            <div class="row">
                <div class="col-md-4">
                    <h5>
                        1. <span id="Workshop_paper" class="workshop-paper">Workshop paper</span><!--
                     --><small><!--
                         --><a onclick="copyLinkToClipboard('Workshop_paper');"
                               style="cursor: pointer;"> üîó<!--
                         --></a><!--
                     --></small><!--
                 --></h5>
                    <ul>
                        <li>Deadline: 2<sup>nd</sup> August, 2024.</li>
                        <li>Follow the ECCV <a href="https://eccv.ecva.net/Conferences/2024/SubmissionPolicies">paper
                            submission policies</a>.
                        </li>
                        <li>Use the same format as for submissions to the main conference: <a
                                href="https://www.overleaf.com/read/hdqrbdhdnmrv#d6ad4f">official ECCV 2024 template</a>.
                        </li>
                        <li>Accepted <span class="workshop-paper">workshop papers</span> should follow the ECCV paper chairs' guidance. <br/> They will most likely
                            communicate to use the <a
                                    href="https://www.overleaf.com/latex/templates/springer-lecture-notes-in-computer-science/kzwwpvhwnvfj#.WuA4JS5uZpi">official
                                Springer ECCV 2024 template</a> for the camera-ready version.
                        </li>
                        <li>Evaluation on the <a
                                href="https://research.nianticlabs.com/mapfree-reloc-benchmark/dataset">Niantic Map-free
                            Relocalization Dataset</a> is encouraged but not required.
                        </li>
                        <li> Please submit at the workshop <a
                                href="https://cmt3.research.microsoft.com/MAPFREEWorkshop2024/Submission/Index">CMT
                            submission portal</a>.<br />
                            Use the "<span class="fw-light">Workshop paper track</span>" category under "Subject areas".
                        </li>
                    </ul>
                </div>
                <div class="col-md-4">
                    <h5>2. <span id="Extended_abstract" class="extended-abstract">Extended abstract</span><!--
                     --><small><!--
                         --><a onclick="copyLinkToClipboard('Extended_abstract');"
                               style="cursor: pointer;"> üîó<!--
                         --></a><!--
                     --></small><!--
                 --></h5>
                    <ul>
                        <li>Deadline: 2<sup>nd</sup> August, 2024.</li>
                        <li>
                            <span class="extended-abstract">Extended abstracts</span> are not subject to the ECCV rules, so they can be in any template (<em>e.g.</em>,
                            <a href="https://www.overleaf.com/read/hdqrbdhdnmrv#d6ad4f">ECCV</a> or
                            <a href="https://github.com/cvpr-org/author-kit/releases">CVPR</a>).
                        </li>
                        <li>The maximum length of <span class="extended-abstract">extended abstracts</span> <b>excluding</b> references is the equivalent
                            of 4 pages in the official <a href="https://github.com/cvpr-org/author-kit/releases">CVPR</a> 2024 format.<br/>
                            <!--See "Dual submissions" in the <a
                                    href="https://eccv.ecva.net/Conferences/2024/SubmissionPolicies">ECCV 2024
                                Submission Policies</a>.
                            <blockquote class="blockquote border-start border-secondary ps-3 my-3">
                                <p class="fs-6"><em>A publication, for the purposes of this policy, is defined to be a
                                    written work longer than <b>four pages (excluding references)</b> that was submitted
                                    for review by peers for either acceptance or rejection, and, after review, was
                                    accepted.</em></p>
                            </blockquote>-->
                        </li>
                        <li><span class="extended-abstract">Extended abstracts</span> can include already published or accepted works, as they are meant to
                            provide authors with the possibility to showcase their ongoing research in areas relevant to
                            map-free relocalization.
                        </li>
                        <li><span class="extended-abstract">Extended abstracts</span> will not be included in the conference proceedings, do not count as paper
                            publication.
                        </li>
                        <li>However, the authors of accepted <span class="extended-abstract">extended abstracts</span> will get the opportunity to present
                            their work at the workshop poster session.
                        </li>
                        <li>Examples of <span class="extended-abstract">extended abstracts</span>:<a
                                href="https://sites.google.com/view/hands2022/program?authuser=0#h.pxvdrcd9tn4j">
                            Accepted Extended Abstracts from HANDS @ ECCV 2022
                        </a>. <em>E.g.</em>, <br/>
                            Scalable High-fidelity 3D Hand Shape Reconstruction via Graph Frequency Decomposition.
                            Tianyu Luan, Jingjing Meng, Junsong Yuan.
                            [<a href="https://drive.google.com/file/d/1JExKfdkt4NaJ7PHS-5Pg1LbXuYyEJd08/view?usp=sharing">pdf</a>]
                        </li>
                        <li>
                            Please submit at the workshop <a
                                href="https://cmt3.research.microsoft.com/MAPFREEWorkshop2024/Submission/Index">CMT
                            submission portal</a>. <br />
                            Use the "<span class="fw-light">Extended abstract track</span>" category under "Subject areas".
                        </li>
                    </ul>
                </div>
                <div class="col-md-4">
                    <h5>3. <span id="Method_description" class="method-description">Method description</span>
                        (~technical report)<!--
                     --><small><!--
                         --><a onclick="copyLinkToClipboard('Method_description');"
                               style="cursor: pointer;"> üîó<!--
                         --></a><!--
                     --></small><!--
                 --></h5>
                    <ul>
                        <li>
                            Challenge leaderboard entry deadline: 23<sup>rd</sup> August, 2024.
                        </li>
                        <li>
                            <span class="method-description">Method description</span> publication deadline:
                            27<sup>th</sup> August, 2024.
                        </li>
                        <li>
                            The minimum required for valid competition entries.
                        </li>
                        <li>
                            Accepted <span class="workshop-paper">workshop papers</span> or accepted
                            <span class="extended-abstract">extended abstracts</span> also qualify as
                            valid <span class="method-description">method descriptions</span>, no need to submit more.
                        </li>
                        <li>
                            Must be publicly available on ArXiv or equivalent. <br/>
                            If there are delays with an ArXiv publication, please send us proof of pending submission.
                        </li>
                        <li>
                            This can be a non-peer reviewed paper in any format (<em>e.g.</em>,
                            <a href="https://www.overleaf.com/read/hdqrbdhdnmrv#d6ad4f">ECCV</a> or
                            <a href="https://github.com/cvpr-org/author-kit/releases">CVPR</a>).
                            The <span class="method-description">method description</span> has to contain sufficient
                            detail for replication of the leaderboard entry's results.
                        </li>
                    </ul>
                </div> <!-- col -->
            </div> <!-- row submission types -->
        </div> <!-- col -->
    </div> <!-- row submission guidelines -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row">
        <div class="col-12">
            <h4><a id="Competition_Requirements">Competition Requirements</a><!--
            --><small><!--
            --><a onclick="copyLinkToClipboard('Competition_Requirements');"
                  style="cursor: pointer;"> üîó<!--
            --></a><!--
          --></small><!--
         --></h4>
            <hr />
            <ul>
                <li>Entries must be submitted within the competition time limits:
                    21<sup>st</sup> May, 2024 - 23<sup>rd</sup> August, 2024.
                </li>
                <li>Entries in the leaderboard that were submitted <b>before</b> the 21<sup>st</sup> May, 2024 will <b>not</b>
                    be considered as participating in the 2024 Map-free Visual Relocalization challenge.
                </li>
                <li>
                    Entries in the leaderboard must point to a valid
                    <span class="method-description">method description</span>
                    (as outlined above under "<b>3. <span class="method-description">Method description</span></b>").
                </li>
            </ul>
        </div>
    </div>

    <!-- --------------------------------------------------------------------------------------- -->

    <!-- FAQ -->
    <div class="row">
        <div class="col-12">
            <h4><a id="FAQ">FAQ</a><!--
            --><small><!--
            --><a onclick="copyLinkToClipboard('FAQ');"
                  style="cursor: pointer;"> üîó<!--
            --></a><!--
          --></small><!--
         --></h4>
            <hr />

            <div class="accordion" id="faqAccordion">
                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingOne">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                                data-bs-target="#collapseOne" aria-expanded="false" aria-controls="collapseOne">
                                <span class="accordion-button-emoji-container">üèÜ‚úÖ<span class="mx-2"></span>üßæ‚ùå</span>
                        </button>
                    </h2>
                    <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne">
                        <div class="accordion-body">
                            <dl>
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>Q</b>:</dt>
                                    <dd class="col">
                                        I would like to participate in the challenge, and I don't have a paper
                                        yet for my method. What should I do?
                                    </dd>
                                </div>
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>A</b>:</dt>
                                    <dd class="col">
                                        You should submit a <span class="workshop-paper">workshop paper</span>
                                        or an <span class="extended-abstract">extended abstract</span> to the workshop,
                                        or make a <span class="method-description">method description</span> available on ArXiv.<br/>
                                        Upon acceptance, your leaderboard entry should refer to the accepted submission.
                                        <br/>
                                        If rejected, make sure to have a <span class="method-description">method description</span>
                                        available on ArXiv to keep your leaderboard entry valid. <br/>
                                        Make sure your leaderboard entry dates between the competition start and end
                                        dates (21<sup>st</sup> May, 2024 - 23<sup>rd</sup> August, 2024).
                                    </dd>
                                </div> <!-- row -->
                            </dl>
                        </div>
                    </div>
                </div> <!-- accordion-item -->

                <!-- --------------- -->

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingTwo">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                                data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
                            <span class="accordion-button-emoji-container">üèÜ‚úÖ<span class="mx-2"></span>üßæ‚úÖ</span>
                        </button>
                    </h2>
                    <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo">
                        <div class="accordion-body">
                            <dl>
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>Q</b>:</dt>
                                    <dd class="col">I would like to participate in the challenge with a method I have
                                        already published. What should I do?
                                    </dd>
                                </div>
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>A</b>:</dt>
                                    <dd class="col">
                                        Make sure your leaderboard entry dates between the competition start and end
                                        dates (21<sup>st</sup> May, 2024 - 23<sup>rd</sup> August, 2024). <br/>
                                        Your leaderboard entry should point to a valid method description, <em>e.g.</em>,
                                        the link to your published paper.
                                    </dd>
                                </div>
                            </dl>
                        </div>
                    </div>
                </div> <!-- accordion-item -->

                <!-- --------------- -->

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingThree">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                                data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
                            <span class="accordion-button-emoji-container">üèÜ‚úÖ<span class="mx-2"></span>üßæ‚úÖ‚ûïüèóÔ∏è</span>
                        </button>
                    </h2>
                    <div id="collapseThree" class="accordion-collapse collapse" aria-labelledby="headingThree">
                        <!--data-bs-parent="#faqAccordion"-->
                        <div class="accordion-body">
                            <dl>
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>Q</b>:</dt>
                                    <dd class="col">
                                        I would like to participate in the challenge with a method I have already
                                        published, but I've made some changes to the method specific to the challenge.
                                        What should I do?
                                    </dd>
                                </div> <!-- row Q -->
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>A</b>:</dt>
                                    <dd class="col">You probably should submit an
                                        <span class="extended-abstract">extended abstract</span> to the workshop or
                                        make a <span class="method-description">method description</span> available on
                                        ArXiv, citing your original work. <br/>
                                        Resubmitting your original work without sufficient amount of differences
                                        compared to the already submitted or published version might violate the ECCV
                                        <a href="https://eccv.ecva.net/Conferences/2024/SubmissionPolicies">policy</a>
                                        regarding dual submissions. <br/>
                                        Make sure your leaderboard entry dates between the competition start and end
                                        dates (21<sup>st</sup> May, 2024 - 23<sup>rd</sup> August, 2024). <br />
                                        Your leaderboard entry should refer to a valid method description,
                                        <em>e.g.</em>, the title of the <span class="extended-abstract">extended abstract</span>
                                        or the link to your <span class="method-description">method description</span> on ArXiv.
                                    </dd>
                                </div>
                            </dl>
                        </div> <!-- accordion-body -->
                    </div> <!-- accordion-collapse -->
                </div> <!-- accordion-item -->

                <!-- --------------- -->

                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingFour">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                                data-bs-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
                            <span class="accordion-button-emoji-container">üèÜ‚ùå<span class="mx-2"></span>üßæüèóÔ∏è</span>
                        </button>
                    </h2>
                    <div id="collapseFour" class="accordion-collapse collapse" aria-labelledby="headingFour">
                        <div class="accordion-body">
                            <dl>
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>Q</b>:</dt>
                                    <dd class="col">
                                        I don't want to participate in the challenge, but I have a paper that has not
                                        been published anywhere else and is not currently under review anywhere. <br />
                                        Can I submit it to the workshop?
                                    </dd>
                                </div> <!-- row Q -->
                                <div class="row">
                                    <dt class="col-auto" style="width: 20px;"><b>A</b>:</dt>
                                    <dd class="col">Yes! Submit it as a <span class="workshop-paper">workshop paper</span>
                                        on the workshop
                                        <a href="https://cmt3.research.microsoft.com/MAPFREEWorkshop2024/Submission/Index">
                                            CMT</a>. <br/>
                                        We encourage you to update the paper with evaluation on the
                                        <a href="https://research.nianticlabs.com/mapfree-reloc-benchmark/dataset">
                                            Niantic Map-free Relocalization Dataset</a>, but it is not required. <br />
                                        If your method can solve the task in the challenge, you should consider also
                                        submitting it to the leaderboard.
                                    </dd>
                                </div> <!-- row A -->
                            </dl>
                        </div> <!-- accordion-body -->
                    </div> <!-- accordion-collapse -->
                </div> <!-- accordion-item -->
            </div> <!-- accordion -->
        </div> <!-- col -->
    </div> <!-- row FAQ -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row mt-4">
        <div class="col-12">
            <p>We look forward to your contributions advancing the field of map-free visual
                relocalization.<br /> For any questions or clarifications, please contact the workshop
                organizers.</p>
        </div>
    </div>

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row align-items-center">
        <div class="col-12">
            <h3><a id="Organizers">Organizers</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Organizers');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />
        </div> <!-- col -->
    </div>

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row justify-content-center">
        <div class="col mugshot-item">
            <a href="https://amonszpart.github.io/">
                <img class="headshot" src="assets/organizers/aron.jpeg"/>
                <span class="name">√Åron Monszpart</span>
                <span class="affiliation">Niantic</span>
            </a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://ebrach.github.io/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/eric.jpeg"/>
                    <span class="name">Eric Brachmann</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://scholar.google.com/citations?user=bSxMRawAAAAJ">
                <div class="item">
                    <img class="headshot" src="assets/organizers/filipe.jpeg"/>
                    <span class="name">Filipe Gaspar</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://guiggh.github.io/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/guillermo.jpeg"/>
                    <span class="name">Guillermo Garcia-Hernando</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://scholar.google.com/citations?user=m_SPRGUAAAAJ&hl=en">
                <div class="item">
                    <img class="headshot" src="assets/organizers/axel.jpeg"/>
                    <span class="name">Axel Barroso-Laguna</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://dantkz.github.io/about/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/daniyar.jpeg"/>
                    <span class="name">Daniyar Turmukhambetov</span>
                    <span class="affiliation">Niantic</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="http://web4.cs.ucl.ac.uk/staff/g.brostow/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/gabriel.jpeg"/>
                    <span class="name">Gabriel J. Brostow</span>
                    <span class="affiliation">Niantic, University College London</span>
                </div><!--
         --></a>
        </div> <!-- col -->
        <div class="col mugshot-item">
            <a href="https://www.robots.ox.ac.uk/~victor/">
                <div class="item">
                    <img class="headshot" src="assets/organizers/victor.jpg"/>
                    <span class="name">Victor Adrian Prisacariu</span>
                    <span class="affiliation">Niantic, University of Oxford</span>
                </div><!--
         --></a>
        </div> <!-- col -->
    </div> <!-- row -->

    <!-- --------------------------------------------------------------------------------------- -->

    <div class="row justify-content-center">
        <div class="col-12">
            <h3><a id="Sponsors">Sponsors</a><!--
            --><small><!--
              --><a
                    onclick="copyLinkToClipboard('Sponsors');"
                    style="cursor: pointer;"> üîó<!--
              --></a><!--
            --></small><!--
         --></h3>
            <hr />
            <div class="row justify-content-center">
                <div class="col col-sm-2"></div>
                <div class="col-sm-auto d-flex justify-content-center">
                    <a href="https://europe.naverlabs.com">
                        <img alt="Naver Labs Europe" src="assets/images/NLE_3_WHITE.png"
                             style="height: 100px; filter: invert(100)"/>
                    </a>
                </div>
                <div class="col-sm-auto d-flex justify-content-center">
                    <a href="https://nianticlabs.com">
                        <img alt="Niantic" src="assets/images/NianticLogo-Large.png"
                             style="height: 100px;"/>
                    </a>
                </div>
                <div class="col col-sm-2"></div>
            </div>
        </div> <!-- col -->
    </div> <!-- row -->

</div> <!-- container -->

<!-- --------------------------------------------------------------------------------------- -->

<footer style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
    <section>
        <p style="text-align: center;">&copy; 2024 Map-free Challenge organizers</p>
        <p style="text-align: center;">
            <a href="https://github.com/nianticlabs/map-free-reloc">GitHub</a>
            <a href="mailto:map-free-workshop@nianticlabs.com" target="_blank">E-mail</a>
        </p>
    </section>
</footer>

<!--<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js" integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r" crossorigin="anonymous"></script>-->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.min.js"
        integrity="sha384-0pUGZvbkm6XF6gxjEnlmuGrJXVbNuzT9qBBavbLwCsOGabYfZo0T0to5eqruptLy"
        crossorigin="anonymous"></script>

<script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>

<script type="text/javascript">
function copyLinkToClipboard(link_name) {
    let parts = window.location.href.split('#');
    let url = (1 < parts.length)
            ? parts[parts.length - 2] + '#' + link_name
            : window.location.href + '#' + link_name;
    navigator.clipboard.writeText(url);
    window.location.href = url;
}

function setSubmissionTypePill(clsName, pillColor, linkName) {
    document.querySelectorAll(clsName).forEach(el => {
        el.classList.add('badge', 'rounded-pill', pillColor);

        // Create a new anchor element
        const link = document.createElement('a');

        // Set the href attribute
        link.href = linkName;

        // Wrap the original element with the new link
        el.parentNode.insertBefore(link, el);
        link.appendChild(el);

        // Add text-decoration-none to the link
        link.classList.add('text-decoration-none');
    });
}

document.addEventListener('DOMContentLoaded', function() {
    setSubmissionTypePill('.workshop-paper', 'bg-success', '#Workshop_paper');
    setSubmissionTypePill('.extended-abstract', 'bg-warning', '#Extended_abstract');
    setSubmissionTypePill('.method-description', 'bg-info', '#Method_description');
});

function updateCountdown(elementId, countDownDate) {
    const now = new Date().getTime();
    const distance = countDownDate - now;

    const days = Math.floor(distance / (86400000)); // 1000 * 60 * 60 * 24
    const hours = Math.floor((distance % (86400000)) / (3600000)); // 1000 * 60 * 60
    const minutes = Math.floor((distance % (3600000)) / (60000)); // 1000 * 60
    const seconds = Math.floor((distance % (60000)) / 1000);

    const element = document.getElementById(elementId);
    if (element) {
        if (distance < 0) {
            element.innerHTML = "";
            return false; // Indicate that the countdown has finished
        } else {
            element.innerHTML = `(${days}d ${hours}h ${minutes}m ${seconds}s)`;
            return true; // Indicate that the countdown should continue
        }
    }
    return false; // If element not found, stop the countdown
}

function addCountdown(elementId, targetDateString) {
    const countDownDate = new Date(targetDateString).getTime();

    // Initial call to set the countdown immediately
    updateCountdown(elementId, countDownDate);

    // Set interval to update every second
    const intervalId = setInterval(function() {
        const shouldContinue = updateCountdown(elementId, countDownDate);
        if (!shouldContinue) {
            clearInterval(intervalId);
        }
    }, 1000);

    return intervalId;
}

document.addEventListener('DOMContentLoaded', function() {
    addCountdown("day-start-countdown", "2024/05/21 00:00:00 UTC");
    addCountdown("day-paper-submit-countdown", "2024/08/02 23:59:59 UTC-12");
    addCountdown("day-paper-camera-ready-countdown", "2024/08/22 23:59:59 UTC-12");
    addCountdown("day-end-countdown", "2024/08/23 23:59:59 UTC-12");
    addCountdown("day-describe-countdown", "2024/08/27 23:59:59 UTC-12");
    addCountdown("day-winners-countdown", "2024/08/30 23:59:59 UTC-12");
    addCountdown("day-workshop-countdown", "2024/09/30 08:00:00 UTC+2");
});
</script>

</body>
</html>
